{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T13:04:50.118671Z",
     "start_time": "2025-10-09T13:04:03.575332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from gmsm.models.mdsv.src.mdsv import MDSV\n",
    "from gmsm.models.mdsv.src.estimation import MDSVEstimator\n",
    "from gmsm.models.mdsv.src.forecasting import MDSVForecaster\n",
    "\n",
    "# Load data with Polars and convert to pandas\n",
    "root = Path().resolve().parent\n",
    "cboe_path = root / 'data' / 'cboe'\n",
    "\n",
    "print(\"Loading data with Polars...\")\n",
    "lazy_df = pl.scan_parquet(cboe_path / '2023' / '*.gzip.parquet')\n",
    "df = lazy_df.collect().to_pandas()\n",
    "\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "print(\"Processing underlying prices...\")\n",
    "underlying_prices = (\n",
    "    df[['quote_datetime', 'active_underlying_price']]\n",
    "    .drop_duplicates(subset=['quote_datetime'])\n",
    "    .sort_values('quote_datetime')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Total observations: {len(underlying_prices)}\")\n",
    "print(f\"Date range: {underlying_prices['quote_datetime'].min()} to {underlying_prices['quote_datetime'].max()}\")\n",
    "\n",
    "# Step 2: Calculate intraday log returns (30-minute returns)\n",
    "# IMPORTANT: This is calculated on INTRADAY data (every 30 minutes)\n",
    "underlying_prices['log_return'] = (\n",
    "    np.log(underlying_prices['active_underlying_price']) -\n",
    "    np.log(underlying_prices['active_underlying_price'].shift(1))\n",
    ")\n",
    "\n",
    "# Calculate squared log returns for realized variance\n",
    "underlying_prices['squared_log_return'] = underlying_prices['log_return'] ** 2\n",
    "\n",
    "# Step 3: Extract date for grouping\n",
    "underlying_prices['date'] = pd.to_datetime(underlying_prices['quote_datetime']).dt.date\n",
    "\n",
    "# Step 4: Calculate DAILY realized variance\n",
    "# Following the paper: RV_t = sum of squared intraday returns, scaled by 100^2\n",
    "print(\"Calculating daily realized variance...\")\n",
    "daily_data = underlying_prices.groupby('date').agg({\n",
    "    'squared_log_return': 'sum',  # Sum of squared intraday returns\n",
    "    'quote_datetime': 'count'      # Number of observations per day\n",
    "}).reset_index()\n",
    "\n",
    "daily_data.columns = ['date', 'sum_squared_returns', 'n_obs']\n",
    "\n",
    "# Scale by 100^2 as per the paper\n",
    "daily_data['realized_variance'] = daily_data['sum_squared_returns'] * (100 ** 2)\n",
    "\n",
    "# Step 5: Calculate DAILY (close-to-close) log returns\n",
    "# Following the paper: \"Daily returns... are computed on a close to close basis\"\n",
    "# Get the last price of each day (close price)\n",
    "print(\"Calculating daily close-to-close returns...\")\n",
    "daily_close_prices = underlying_prices.groupby('date').agg({\n",
    "    'active_underlying_price': 'last'  # Last price of the day = close price\n",
    "}).reset_index()\n",
    "\n",
    "daily_close_prices.columns = ['date', 'close_price']\n",
    "\n",
    "# Calculate close-to-close log returns\n",
    "daily_close_prices['daily_log_return'] = (\n",
    "    np.log(daily_close_prices['close_price']) -\n",
    "    np.log(daily_close_prices['close_price'].shift(1))\n",
    ")\n",
    "\n",
    "# Scale by 100 (in percentage terms) as per the paper\n",
    "daily_close_prices['daily_log_return_pct'] = daily_close_prices['daily_log_return'] * 100\n",
    "\n",
    "# Step 6: Merge daily returns with realized variance\n",
    "daily_data = daily_data.merge(\n",
    "    daily_close_prices[['date', 'daily_log_return_pct']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 7: Demean the daily returns as per the paper\n",
    "# \"demeaned, and expressed in percentages\"\n",
    "mean_return = daily_data['daily_log_return_pct'].mean()\n",
    "daily_data['demeaned_log_return'] = daily_data['daily_log_return_pct'] - mean_return\n",
    "\n",
    "# Step 8: Create forward-looking realized variance (prediction target)\n",
    "# RV_{t+1} is what we want to predict based on information available at time t\n",
    "daily_data['forward_realized_variance'] = daily_data['realized_variance'].shift(-1)\n",
    "\n",
    "# Step 9: Remove first row (no return) and last row (no forward RV)\n",
    "daily_data = daily_data.iloc[1:-1].reset_index(drop=True)\n"
   ],
   "id": "776ed98c618a146f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data with Polars...\n",
      "Loaded 38802410 rows\n",
      "Processing underlying prices...\n",
      "Total observations: 2988\n",
      "Date range: 2023-01-03 09:31:00-05:00 to 2023-12-29 16:00:00-05:00\n",
      "Calculating daily realized variance...\n",
      "Calculating daily close-to-close returns...\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T12:09:24.844291Z",
     "start_time": "2025-10-09T12:09:24.796732Z"
    }
   },
   "cell_type": "code",
   "source": "phdaily_data",
   "id": "f809a72d7de9393b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           date  sum_squared_returns  n_obs  realized_variance  \\\n",
       "0    2023-01-04             0.000179     12           1.786900   \n",
       "1    2023-01-05             0.000084     12           0.837126   \n",
       "2    2023-01-06             0.000154     12           1.537528   \n",
       "3    2023-01-09             0.000094     12           0.944130   \n",
       "4    2023-01-10             0.000021     12           0.211935   \n",
       "..          ...                  ...    ...                ...   \n",
       "243  2023-12-21             0.000099     12           0.986300   \n",
       "244  2023-12-22             0.000050     12           0.502645   \n",
       "245  2023-12-26             0.000007     12           0.068773   \n",
       "246  2023-12-27             0.000008     12           0.084854   \n",
       "247  2023-12-28             0.000004     12           0.044457   \n",
       "\n",
       "     daily_log_return_pct  demeaned_log_return  forward_realized_variance  \n",
       "0                0.748327             0.659417                   0.837126  \n",
       "1               -1.167722            -1.256631                   1.537528  \n",
       "2                2.234695             2.145785                   0.944130  \n",
       "3               -0.054197            -0.143106                   0.211935  \n",
       "4                0.694113             0.605203                   0.765736  \n",
       "..                    ...                  ...                        ...  \n",
       "243              1.033222             0.944312                   0.502645  \n",
       "244              0.173011             0.084101                   0.068773  \n",
       "245              0.418657             0.329748                   0.084854  \n",
       "246              0.151397             0.062487                   0.044457  \n",
       "247              0.029060            -0.059849                   0.293019  \n",
       "\n",
       "[248 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sum_squared_returns</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>realized_variance</th>\n",
       "      <th>daily_log_return_pct</th>\n",
       "      <th>demeaned_log_return</th>\n",
       "      <th>forward_realized_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>12</td>\n",
       "      <td>1.786900</td>\n",
       "      <td>0.748327</td>\n",
       "      <td>0.659417</td>\n",
       "      <td>0.837126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>12</td>\n",
       "      <td>0.837126</td>\n",
       "      <td>-1.167722</td>\n",
       "      <td>-1.256631</td>\n",
       "      <td>1.537528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>12</td>\n",
       "      <td>1.537528</td>\n",
       "      <td>2.234695</td>\n",
       "      <td>2.145785</td>\n",
       "      <td>0.944130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>12</td>\n",
       "      <td>0.944130</td>\n",
       "      <td>-0.054197</td>\n",
       "      <td>-0.143106</td>\n",
       "      <td>0.211935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>12</td>\n",
       "      <td>0.211935</td>\n",
       "      <td>0.694113</td>\n",
       "      <td>0.605203</td>\n",
       "      <td>0.765736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2023-12-21</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>12</td>\n",
       "      <td>0.986300</td>\n",
       "      <td>1.033222</td>\n",
       "      <td>0.944312</td>\n",
       "      <td>0.502645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>12</td>\n",
       "      <td>0.502645</td>\n",
       "      <td>0.173011</td>\n",
       "      <td>0.084101</td>\n",
       "      <td>0.068773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>12</td>\n",
       "      <td>0.068773</td>\n",
       "      <td>0.418657</td>\n",
       "      <td>0.329748</td>\n",
       "      <td>0.084854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>12</td>\n",
       "      <td>0.084854</td>\n",
       "      <td>0.151397</td>\n",
       "      <td>0.062487</td>\n",
       "      <td>0.044457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>12</td>\n",
       "      <td>0.044457</td>\n",
       "      <td>0.029060</td>\n",
       "      <td>-0.059849</td>\n",
       "      <td>0.293019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fit MDSV",
   "id": "7d3e1c690d4a472c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T13:01:16.750320Z",
     "start_time": "2025-10-09T13:01:16.733405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mdsv_input = daily_data[['date', 'demeaned_log_return', 'realized_variance']]\n",
    "\n",
    "test_size = len(mdsv_input) // 3\n",
    "train_data = mdsv_input.iloc[:-test_size].copy()\n",
    "test_data = mdsv_input.iloc[-test_size:].copy()\n",
    "\n",
    "train_returns = train_data['demeaned_log_return'].values\n",
    "train_rv = train_data['realized_variance'].values\n",
    "train_joint = np.column_stack([train_returns, train_rv])"
   ],
   "id": "6adc0aa03db1f74e",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T13:08:00.556443Z",
     "start_time": "2025-10-09T13:08:00.550534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MDSV(N=3, D=10, model_type=2, leverage=True)\n",
    "estimator = MDSVEstimator(model)"
   ],
   "id": "4de85b76667527f9",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T14:49:49.530091Z",
     "start_time": "2025-10-09T13:40:37.333565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add MDSV package to path\n",
    "root = Path().resolve().parent\n",
    "mdsv_path = root / 'mdsv-main'\n",
    "sys.path.append(str(mdsv_path))\n",
    "\n",
    "from gmsm.models.mdsv.src.mdsv import MDSV, MDSVResult\n",
    "from gmsm.models.mdsv.src.estimation import MDSVEstimator, EstimationOptions\n",
    "from gmsm.models.mdsv.src.forecasting import MDSVForecaster\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Load Preprocessed Data\n",
    "# ============================================================================\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 1: LOADING PREPROCESSED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "data_path = root / 'data' / 'processed' / 'daily_data_2015_2024.csv'\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "\n",
    "mdsv_input = pd.read_csv(data_path)\n",
    "mdsv_input['date'] = pd.to_datetime(mdsv_input['date'])\n",
    "\n",
    "print(f\"\\nTotal days: {len(mdsv_input)}\")\n",
    "print(f\"Date range: {mdsv_input['date'].min()} to {mdsv_input['date'].max()}\")\n",
    "\n",
    "# Check for NaN values\n",
    "print(f\"\\nChecking for missing values:\")\n",
    "print(mdsv_input[['demeaned_log_return', 'realized_variance']].isna().sum())\n",
    "\n",
    "# Remove any rows with NaN values\n",
    "mdsv_input_clean = mdsv_input.dropna(subset=['demeaned_log_return', 'realized_variance']).reset_index(drop=True)\n",
    "print(f\"\\nAfter removing NaN: {len(mdsv_input_clean)} days\")\n",
    "print(f\"Date range: {mdsv_input_clean['date'].min()} to {mdsv_input_clean['date'].max()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Train/Test Split\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 2: TRAIN/TEST SPLIT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use last year as test set\n",
    "test_size = 252  # Approximately 1 trading year\n",
    "train_data = mdsv_input_clean.iloc[:-test_size].copy()\n",
    "test_data = mdsv_input_clean.iloc[-test_size:].copy()\n",
    "\n",
    "print(f\"Train set: {len(train_data)} days ({train_data['date'].min()} to {train_data['date'].max()})\")\n",
    "print(f\"Test set: {len(test_data)} days ({test_data['date'].min()} to {test_data['date'].max()})\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Fit MDSV Model using MDSVEstimator\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 3: FITTING MDSV MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare training data: returns and RV as columns\n",
    "train_returns = train_data['demeaned_log_return'].values\n",
    "train_rv = train_data['realized_variance'].values\n",
    "train_joint = np.column_stack([train_returns, train_rv])\n",
    "\n",
    "print(f\"\\nTraining data shape: {train_joint.shape}\")\n",
    "print(f\"  Column 0 (returns): mean={train_returns.mean():.4f}, std={train_returns.std():.4f}\")\n",
    "print(f\"  Column 1 (RV): mean={train_rv.mean():.4f}, std={train_rv.std():.4f}\")\n",
    "print(f\"  Returns range: [{train_returns.min():.4f}, {train_returns.max():.4f}]\")\n",
    "print(f\"  RV range: [{train_rv.min():.4f}, {train_rv.max():.4f}]\")\n",
    "\n",
    "# Initialize MDSV model with smaller dimensions for faster fitting\n",
    "print(\"\\nInitializing MDSV(2, 5) model with leverage...\")\n",
    "model = MDSV(\n",
    "    N=2,              # Number of components\n",
    "    D=5,              # States per component\n",
    "    model_type=2,     # Joint model (0=returns only, 1=RV only, 2=joint)\n",
    "    leverage=True     # Include leverage effect\n",
    ")\n",
    "\n",
    "# Use MDSVEstimator for proper estimation (following the example)\n",
    "print(\"\\nSetting up MDSVEstimator with options...\")\n",
    "estimator = MDSVEstimator(model)\n",
    "\n",
    "# Create estimation options\n",
    "options = EstimationOptions(\n",
    "    method='L-BFGS-B',\n",
    "    maxiter=1000,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"\\nFitting model using MDSVEstimator (this will take several minutes)...\")\n",
    "print(\"This is the proper way to fit the model - please be patient...\\n\")\n",
    "\n",
    "try:\n",
    "    result = estimator.estimate(\n",
    "        data=train_joint,\n",
    "        options=options\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MODEL FITTING RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Success: {result.success}\")\n",
    "    print(f\"Log-likelihood: {result.log_likelihood:.2f}\")\n",
    "    print(f\"BIC: {result.bic:.2f}\")\n",
    "    print(f\"AIC: {result.aic:.2f}\")\n",
    "    print(f\"Number of iterations: {result.nit if hasattr(result, 'nit') else 'N/A'}\")\n",
    "\n",
    "    print(\"\\nEstimated Parameters:\")\n",
    "    for param_name, param_value in result.parameters.items():\n",
    "        if isinstance(param_value, (int, float, np.floating)):\n",
    "            print(f\"  {param_name}: {param_value:.6f}\")\n",
    "        elif isinstance(param_value, np.ndarray):\n",
    "            if param_value.size <= 10:\n",
    "                print(f\"  {param_name}: {param_value}\")\n",
    "            else:\n",
    "                print(f\"  {param_name}: shape={param_value.shape}, mean={param_value.mean():.6f}\")\n",
    "        else:\n",
    "            print(f\"  {param_name}: {type(param_value)}\")\n",
    "\n",
    "    # Check if model fitted successfully\n",
    "    if not np.isfinite(result.log_likelihood):\n",
    "        raise ValueError(\"Model fitting failed - log-likelihood is not finite\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError during fitting: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"\\nTrying simpler model (no leverage)...\")\n",
    "\n",
    "    # Fallback: simpler model without leverage\n",
    "    model = MDSV(N=2, D=5, model_type=2, leverage=False)\n",
    "    estimator = MDSVEstimator(model)\n",
    "\n",
    "    result = estimator.estimate(\n",
    "        data=train_joint,\n",
    "        options=options\n",
    "    )\n",
    "    print(f\"\\nFallback model results:\")\n",
    "    print(f\"Log-likelihood: {result.log_likelihood:.2f}\")\n",
    "    print(f\"BIC: {result.bic:.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: One-Step Ahead Forecasting\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 4: ONE-STEP AHEAD FORECASTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create forecaster with the fitted model\n",
    "print(\"\\nInitializing forecaster with fitted model...\")\n",
    "forecaster = MDSVForecaster(model)\n",
    "\n",
    "# Generate rolling forecasts\n",
    "print(\"\\nGenerating one-step ahead forecasts...\")\n",
    "print(\"Using expanding window approach (re-estimating is too slow)...\\n\")\n",
    "\n",
    "predictions_rv = []\n",
    "actuals_rv = []\n",
    "prediction_errors = []\n",
    "\n",
    "# For each test point, use all data up to that point to forecast\n",
    "for i in range(len(test_data)):\n",
    "    try:\n",
    "        # Data available up to time t (for forecasting t+1)\n",
    "        if i == 0:\n",
    "            # First forecast: use only training data\n",
    "            available_returns = train_returns\n",
    "            available_rv = train_rv\n",
    "        else:\n",
    "            # Subsequent forecasts: add observed test data up to (but not including) current point\n",
    "            available_returns = np.concatenate([\n",
    "                train_returns,\n",
    "                test_data['demeaned_log_return'].iloc[:i].values\n",
    "            ])\n",
    "            available_rv = np.concatenate([\n",
    "                train_rv,\n",
    "                test_data['realized_variance'].iloc[:i].values\n",
    "            ])\n",
    "\n",
    "        available_data = np.column_stack([available_returns, available_rv])\n",
    "\n",
    "        # Get last observation for conditioning (leverage effect)\n",
    "        last_obs = available_data[-1:]\n",
    "\n",
    "        # Forecast 1-step ahead\n",
    "        forecast = forecaster.forecast(\n",
    "            n_ahead=1,\n",
    "            last_obs=last_obs,\n",
    "            n_simulations=10000  # More simulations for better accuracy\n",
    "        )\n",
    "\n",
    "        # Extract RV forecast (handle different return formats)\n",
    "        if isinstance(forecast, dict):\n",
    "            if 'rv' in forecast:\n",
    "                pred_rv = forecast['rv'][0] if hasattr(forecast['rv'], '__len__') else forecast['rv']\n",
    "            elif 'volatility' in forecast:\n",
    "                pred_rv = forecast['volatility'][0] if hasattr(forecast['volatility'], '__len__') else forecast['volatility']\n",
    "            else:\n",
    "                # Try to get first value from forecast dict\n",
    "                pred_rv = list(forecast.values())[0]\n",
    "                if hasattr(pred_rv, '__len__'):\n",
    "                    pred_rv = pred_rv[0]\n",
    "        else:\n",
    "            pred_rv = forecast[0] if hasattr(forecast, '__len__') else forecast\n",
    "\n",
    "        predictions_rv.append(pred_rv)\n",
    "        actuals_rv.append(test_data['realized_variance'].iloc[i])\n",
    "\n",
    "        if (i + 1) % 50 == 0 or i == 0:\n",
    "            print(f\"  Forecast {i+1}/{len(test_data)}: predicted={pred_rv:.4f}, actual={test_data['realized_variance'].iloc[i]:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Error at forecast {i+1}: {e}\")\n",
    "        predictions_rv.append(np.nan)\n",
    "        actuals_rv.append(test_data['realized_variance'].iloc[i])\n",
    "        prediction_errors.append(str(e))\n",
    "\n",
    "predictions_rv = np.array(predictions_rv)\n",
    "actuals_rv = np.array(actuals_rv)\n",
    "\n",
    "print(f\"\\nCompleted {len(predictions_rv)} forecasts\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 5: Evaluate Performance\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 5: FORECAST EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Remove NaN predictions\n",
    "valid_mask = ~np.isnan(predictions_rv) & ~np.isnan(actuals_rv)\n",
    "predictions_valid = predictions_rv[valid_mask]\n",
    "actuals_valid = actuals_rv[valid_mask]\n",
    "\n",
    "print(f\"\\nValid forecasts: {len(predictions_valid)}/{len(predictions_rv)}\")\n",
    "\n",
    "if len(predictions_valid) > 10:  # Need reasonable sample size\n",
    "    # Calculate error metrics\n",
    "    errors = predictions_valid - actuals_valid\n",
    "    squared_errors = errors ** 2\n",
    "    abs_errors = np.abs(errors)\n",
    "\n",
    "    rmse = np.sqrt(np.mean(squared_errors))\n",
    "    mae = np.mean(abs_errors)\n",
    "    mape = np.mean(np.abs(errors / actuals_valid)) * 100\n",
    "\n",
    "    # Median metrics (more robust to outliers)\n",
    "    median_ae = np.median(abs_errors)\n",
    "\n",
    "    print(f\"\\nMDSV Forecast Performance:\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE: {mae:.4f}\")\n",
    "    print(f\"  Median AE: {median_ae:.4f}\")\n",
    "    print(f\"  MAPE: {mape:.2f}%\")\n",
    "\n",
    "    print(f\"\\nActual RV statistics (test period):\")\n",
    "    print(f\"  Mean: {actuals_valid.mean():.4f}\")\n",
    "    print(f\"  Std: {actuals_valid.std():.4f}\")\n",
    "    print(f\"  Median: {np.median(actuals_valid):.4f}\")\n",
    "\n",
    "    print(f\"\\nPredicted RV statistics:\")\n",
    "    print(f\"  Mean: {predictions_valid.mean():.4f}\")\n",
    "    print(f\"  Std: {predictions_valid.std():.4f}\")\n",
    "    print(f\"  Median: {np.median(predictions_valid):.4f}\")\n",
    "\n",
    "    # Naive benchmark (persistence/random walk model)\n",
    "    print(f\"\\n\" + \"-\"*80)\n",
    "    print(\"BENCHMARK COMPARISON\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "    # Persistence: RV_t predicts RV_{t+1}\n",
    "    naive_predictions = test_data['realized_variance'].iloc[:-1].values\n",
    "    naive_actuals = test_data['realized_variance'].iloc[1:].values\n",
    "    naive_mask = ~np.isnan(naive_predictions) & ~np.isnan(naive_actuals)\n",
    "\n",
    "    naive_rmse = np.sqrt(np.mean((naive_predictions[naive_mask] - naive_actuals[naive_mask]) ** 2))\n",
    "    naive_mae = np.mean(np.abs(naive_predictions[naive_mask] - naive_actuals[naive_mask]))\n",
    "\n",
    "    print(f\"\\nNaive (Persistence) Forecast:\")\n",
    "    print(f\"  RMSE: {naive_rmse:.4f}\")\n",
    "    print(f\"  MAE: {naive_mae:.4f}\")\n",
    "\n",
    "    improvement_rmse = ((naive_rmse - rmse) / naive_rmse * 100)\n",
    "    improvement_mae = ((naive_mae - mae) / naive_mae * 100)\n",
    "\n",
    "    print(f\"\\nMDSV vs Naive:\")\n",
    "    if improvement_rmse > 0:\n",
    "        print(f\"  ✓ RMSE improvement: {improvement_rmse:.2f}%\")\n",
    "    else:\n",
    "        print(f\"  ✗ RMSE worse by: {abs(improvement_rmse):.2f}%\")\n",
    "\n",
    "    if improvement_mae > 0:\n",
    "        print(f\"  ✓ MAE improvement: {improvement_mae:.2f}%\")\n",
    "    else:\n",
    "        print(f\"  ✗ MAE worse by: {abs(improvement_mae):.2f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n✗ Insufficient valid forecasts for evaluation!\")\n",
    "    if len(prediction_errors) > 0:\n",
    "        print(f\"\\nSample errors encountered:\")\n",
    "        for err in prediction_errors[:5]:\n",
    "            print(f\"  - {err}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Save Results\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STEP 6: SAVING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_path = root / 'data' / 'results'\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save predictions\n",
    "forecast_df = pd.DataFrame({\n",
    "    'date': test_data['date'].values,\n",
    "    'actual_rv': actuals_rv,\n",
    "    'predicted_rv': predictions_rv,\n",
    "    'error': actuals_rv - predictions_rv,\n",
    "    'squared_error': (actuals_rv - predictions_rv) ** 2,\n",
    "    'abs_error': np.abs(actuals_rv - predictions_rv)\n",
    "})\n",
    "\n",
    "forecast_df.to_csv(output_path / 'mdsv_forecasts_2015_2024.csv', index=False)\n",
    "print(f\"\\n✓ Forecasts saved to: {output_path / 'mdsv_forecasts_2015_2024.csv'}\")\n",
    "\n",
    "# Save model info\n",
    "model_info = {\n",
    "    'model_specification': {\n",
    "        'N': model.N,\n",
    "        'D': model.D,\n",
    "        'model_type': model.model_type,\n",
    "        'leverage': model.leverage\n",
    "    },\n",
    "    'estimation_results': {\n",
    "        'log_likelihood': float(result.log_likelihood),\n",
    "        'aic': float(result.aic),\n",
    "        'bic': float(result.bic),\n",
    "        'success': result.success if hasattr(result, 'success') else None\n",
    "    },\n",
    "    'data_info': {\n",
    "        'train_size': len(train_data),\n",
    "        'test_size': len(test_data),\n",
    "        'train_period': f\"{train_data['date'].min()} to {train_data['date'].max()}\",\n",
    "        'test_period': f\"{test_data['date'].min()} to {test_data['date'].max()}\"\n",
    "    },\n",
    "    'forecast_performance': {\n",
    "        'valid_forecasts': int(len(predictions_valid)),\n",
    "        'total_forecasts': int(len(predictions_rv)),\n",
    "        'rmse': float(rmse) if len(predictions_valid) > 10 else None,\n",
    "        'mae': float(mae) if len(predictions_valid) > 10 else None,\n",
    "        'mape': float(mape) if len(predictions_valid) > 10 else None,\n",
    "        'naive_rmse': float(naive_rmse) if len(predictions_valid) > 10 else None,\n",
    "        'improvement_pct': float(improvement_rmse) if len(predictions_valid) > 10 else None\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(output_path / 'mdsv_model_info_2015_2024.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "print(f\"✓ Model info saved to: {output_path / 'mdsv_model_info_2015_2024.json'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PIPELINE COMPLETED\")\n",
    "print(\"=\"*80)"
   ],
   "id": "e3201285261cc5fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1: LOADING PREPROCESSED DATA\n",
      "================================================================================\n",
      "Loading data from: /Users/gregruyoga/gmoneycodes/gmsm/gmsm/data/processed/daily_data_2015_2024.csv\n",
      "\n",
      "Total days: 2498\n",
      "Date range: 2015-01-05 00:00:00 to 2024-12-05 00:00:00\n",
      "\n",
      "Checking for missing values:\n",
      "demeaned_log_return    9\n",
      "realized_variance      0\n",
      "dtype: int64\n",
      "\n",
      "After removing NaN: 2489 days\n",
      "Date range: 2015-01-05 00:00:00 to 2024-12-05 00:00:00\n",
      "\n",
      "================================================================================\n",
      "STEP 2: TRAIN/TEST SPLIT\n",
      "================================================================================\n",
      "Train set: 2237 days (2015-01-05 00:00:00 to 2023-12-04 00:00:00)\n",
      "Test set: 252 days (2023-12-05 00:00:00 to 2024-12-05 00:00:00)\n",
      "\n",
      "================================================================================\n",
      "STEP 3: FITTING MDSV MODEL\n",
      "================================================================================\n",
      "\n",
      "Training data shape: (2237, 2)\n",
      "  Column 0 (returns): mean=-0.0081, std=1.1578\n",
      "  Column 1 (RV): mean=1.1815, std=3.8702\n",
      "  Returns range: [-12.8532, 8.9716]\n",
      "  RV range: [0.0111, 90.9579]\n",
      "\n",
      "Initializing MDSV(2, 5) model with leverage...\n",
      "\n",
      "Setting up MDSVEstimator with options...\n",
      "\n",
      "Fitting model using MDSVEstimator (this will take several minutes)...\n",
      "This is the proper way to fit the model - please be patient...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregruyoga/gmoneycodes/gmsm/gmsm/models/mdsv/src/mdsv.py:358: RuntimeWarning: overflow encountered in exp\n",
      "  lognorm.pdf(rv, s=np.sqrt(shape), scale=np.exp(mu_rv)))\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2a8425409349c0ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
